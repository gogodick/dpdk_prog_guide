
# 3. 环境抽象层
环境抽象层（EAL）负责访问底层资源，例如硬件和内存空间。它提供了通用接口，对应用和库隐藏了环境细节。初始化程序需要决定如何分配资源（内存空间，PCI设备，定时器，控制台等等）。

EAL的典型服务包括：

* DPDK加载和启动：DPDK和应用被链接成一个应用，必须通过某些方式加载。
* CPU核亲和性和分配方式：EAL支持把执行单元分配到指定的CPU核，以及创建执行实例。
* 预留系统内存：EAL支持预留不同的内存区域，例如设备交互的物理内存。
* PCI地址抽象：EAL提供了访问PCI地址空间的接口。
* 跟踪和调试功能：Logs，dump_stack，panic等等。
* 共用功能：libc不支持的自旋锁和原子计数器。
* CPU特性识别：运行时检测CPU特性，例如Intel AVX是否支持。检测当前CPU是否支持binary编译的特性。
* 中断处理：对特定中断源提供注册和注销回调函数的接口。
* 告警函数：指定时间运行的设置和删除回调函数的接口。
## 3.1. Linux用户态环境的EAL
在Linux用户态环境，DPDK应用使用pthread库作为用户态应用运行。DPDK需要的PCI信息包括设备和地址空间，使用/sys内核接口获取信息，使用的内核模块包括uio_pci_generic或者igb_uio。参考Linux内核的UIO文档。内存是mmap到应用的地址空间的。

EAL在hugetlbfs（使用huge page提高性能）使用mmap()函数分配物理内存。内存暴露给DPDK服务层，比如Mempool库。

在这个时候，完成了DPDK服务层初始化，然后设置pthread的affinity，每个执行单元会被分配到指定的逻辑CPU核，作为用户线程执行。

时间的来源是，通过mmap()调用从CPU时间戳（TSC）或者HPET内核API获取。

### 3.1.1. 初始化和CPU核启动
部分初始化是glibc的start函数完成的。初始化时，会执行检查来保证CPU支持config文件指定的微架构。然后，调用main()函数。核心初始化和启动在rte_eal_init()完成（参考API文档）。包括了对pthread库的调用（具体是pthread_self()，pthread_create()和pthread_setaffinity_np()）。

![Fig. 3.1 EAL Initialization in a Linux Application Environment](https://github.com/gogodick/dpdk_prog_guide/blob/master/Image/linuxapp_launch.svg)

| 注意|
| :---|
| 对象的初始化，比如内存区域，ring，内存池，lpm表和hash表，应该在主logical核上作为应用初始化的一部分执行。这些对象的创建和初始化函数不是线程安全的。 但是，初始化完成后，这些对象可以在多线程环境下安全使用。|

### 3.1.2. 多进程支持
Linuxapp的EAL支持多进程和多线程（pthread）模型。[Multi-process Support](https://github.com/gogodick/dpdk_prog_guide/blob/master/Text/28.md)提供了更多细节。

### 3.1.3. 发现内存映射和预留内存
分配大块连续物理内存是由hugetlbfs内核文件系统完成的。EAL提供了API在这个连续内存中预留有名字的内存区域。内存区域预留API还会返回内存的物理地址。

| 注意|
| :---|
| 使用rte_malloc预留的内存也来自hugetlbfs文件系统的内存page。 |

### 3.1.4. PCI访问
EAL使用内核提供的/sys/bus/pci扫描PCI总线上的设备。为了访问PCI内存，uio_pci_generic内核模块提供了/dev/uioX设备文件，和/sys的资源文件，mmap到应用从而能够访问PCI地址空间。DPDK特有的igb_uio驱动也有相同的效果。两个驱动都使用了uio内核特性（用户态驱动）。

### 3.1.5. 每core的独立变量和共享变量
| 注意|
| :---|
| lcore表示处理器的逻辑执行单元，有时候叫做硬件线程|

共享变量是缺省行为。每core的独立变量通过Thread Local Storage (TLS)实现，提供了每个thread的本地存储。

### 3.1.6. Logs
logging API是EAL提供的。缺省情况下，Linux应用把log发送到syslog和控制台。但是用户可以覆盖log函数，从而使用不同的logging机制。

#### 3.1.6.1. 跟踪和调试功能
glibc有一些调试函数可以打印调用栈。rte_panic()函数会主动发出SIG_ABORT信号，生成gdb可以读的core文件。

### 3.1.7. 识别CPU特性
EAL可以在运行时查询CPU（使用rte_cpu_get_features()函数），确定有哪些CPU特性。

### 3.1.8. 用户态中断事件
* host线程处理用户态中断和警报  
EAL创建host线程，轮询UIO设备文件描述符来检测中断。EAL函数可以注册和注销指定中断事件的回调函数，，host线程会异步调用回调函数。EAL还运行像NIC中断一样使用定时回调函数。

| 注意|
| :---|
| DPDK PMD中，host线程处理的中断只有link状态改变（link up和link down）和设备移除。|

* RX中断事件  
PMD提供的接收和发送函数没有限制只能在轮询线程模式下执行。为了优化对小流量的轮询，暂停轮询并且等待唤醒事件是有作用的。RX中断是这类唤醒事件的首选，单不一定是唯一选择。

EAL为这种事件驱动模型提供了事件API。以linuxapp为例，实现基于epoll。每个线程可以监控一个epoll实例，所有的唤醒事件的文件描述符都添加到这个epoll实例。根据UIO/VFIO标准，创建事件文件描述符，并且映射到中断向量。对于bsdapp，可以使用kqueue，但是还没有实现。

EAL初始化事件文件描述符和中断向量之间的映射，而每个设备初始化中断向量和队列。通过这种方式，EAL实际上不知道特定向量的中断原因。eth_dev驱动负责编写第二种映射。

| 注意|
| :---|
| 只有VFIO才支持每队列的RX中断事件，因为VFIO支持多个MSI-X向量。在UIO里，RX中断向量和其他中断使用同样的向量。所以，RX中断和LSC（link状态变化）中断同时使能（intr_conf.lsc == 1 && intr_conf.rxq == 1），只有前者生效|

RX中断通过ethdev API控制，打开和关闭，‘rte_eth_dev_rx_intr_\*’。如果PMD不支持，返回失败。intr_conf.rxq标志位用来打开设备的RX中断能力。

* 设备移除事件  
设备在总线移除会触发这个事件。设备资源会无法访问（例如解除PCI映射）。PMD必须保证，在这种情况下应用能够安全的使用回调函数。

这个事件可以和link状态变化事件一样使用。所以执行环境是一样的，例如专用的中断host线程。

考虑这种情况，应用可能想要关闭发出设备移除事件的设备。在这个场景下，调用rte_eth_dev_close()会注销它自己的设备移除事件的回调函数。要注意不能在中断处理中关闭设备。有必要重新调度这个关闭操作。

### 3.1.9. 黑名单
EAL的PCI设备黑名单功能可以把指定NIC端口加入黑名单，DPDK就会忽略这些NIC端口。这些要加入黑名单的端口通过PCIE地址描述（Domain:Bus:Device.Function）。

### 3.1.10. 其他函数
锁和原子操作是基于特定架构的（i686和x86_64）。

## 3.2. 内存段和内存区域 (memzone)
EAL的这个功能提供了物理内存的映射。因为物理内存可以不连续，使用descriptor表描述内存，每个descriptor（称为rte_memseg）描述了一块连续的内存。

在此基础上，memzone分配器的责任是预留连续的物理内存。使用唯一的名字来识别这些内存区域。

配置结构也包括rte_memzone descriptor。使用rte_eal_get_configuration()访问这个结构。通过名字查找内存区域会返回包含这个内存区域物理地址的descriptor。

预留内存区域时，可以指定对齐参数（缺省按cache line对齐），从而得到指定对齐的开始地址。对齐参数必须是2的指数，而且不能小于cache line的大小（64字节）。内存区域可以是2 MB或者1 GB的hugepage，系统支持这两种配置。

## 3.3. 多线程
DPDK通常把一个线程绑定到一个core，避免任务切换的开销。这种方式提高了性能，但是缺乏灵活性，不总是有效。

电源管理通过限制CPU频率来提高CPU的效率。但是也可能利用CPU的空闲周期来提高CPU的使用效率。

使用cgroup，可以方便的分配CPU使用量。这也是一种提高CPU效率的方式，但是先决条件是：DPDK必须处理每个核的多线程的上下文切换。

为了更加灵活，可以对CPU集合而不只是CPU设置线程亲和性。

### 3.3.1. EAL线程和逻辑核亲和性
“lcore”表示EAl线程，实际上是Linux/FreeBSD的pthread。“EAL pthread”是由EAL创建和管理的，执行remote_launch分配的任务。每个EAL线程都有一个TLS（Thread local Storage），叫做_lcore_id，用来识别线程。EAL线程总是按照1：1的方式和物理CPU绑定，_lcore_id一般等于CPU ID。

当使用多线程时，EAL线程和物理CPU不总是1：1的关系。EAL线程可以绑定到一个CPU集合，这时_lcore_id不等于CPU ID。因为这个原因，定义了一个EAL选项“-lcore”，设置逻辑核的CPU亲和性。对一个指定逻辑核ID或者ID组，这个选项运行为EAL线程设置CPU集合。

<b>选项格式：</b>  
> –lcores=’<lcore_set>[@cpu_set][,<lcore_set>[@cpu_set],...]’
‘lcore_set’ and ‘cpu_set’ can be a single number, range or a group.

数字的表示方式是“digit([0-9]+)”；范围的表示方式是“<number>-<number>”；组的表示方式是“(<number|range>[,<number|range>,...])”。

如果没有提供‘@cpu_set’，‘cpu_set’会缺省为‘lcore_set’。

```
例如，“--lcores='1,2@(5-7),(3-5)@(0,2),(0,6),7-8'”表示运行9个EAL线程；
    lcore 0在cpuset 0x41 （cpu 0，6）运行；
    lcore 1在cpuset 0x2 （cpu 1）运行；
    lcore 2在cpuset 0xe0 （cpu 5，6，7）运行；
    lcore 3，4，5在cpuset 0x5（cpu 0，2）运行；
    lcore 6在cpuset 0x41 （cpu 0，6）运行；
    lcore 7在cpuset 0x80 （cpu 7）运行；
    lcore 8在cpuset 0x100 （cpu 8）运行。
```
通过这个选项，可以为每个lcore ID分配关联CPU。这个选项还和corelist（‘-l’）选项兼容。

### 3.3.2. 非EAL线程的支持
可以在任何用户线程（也就是非EAL线程）执行DPDK。在非EAL线程里，_lcore_id总是LCORE_ID_ANY，表示这不是EAl线程，而EAL线程会有一个有效唯一的_lcore_id。有的库会使用唯一的ID（例如TID），有的库没有影响，还有一些库可以工作但是收到限制（例如timer和mempool库）。

所有这些影响在已知问题部分介绍。

### 3.3.3. 公共线程API
线程有两个公共API，rte_thread_set_affinity()和rte_thread_get_affinity()。在任何线程中使用这些API时，会读写Thread Local Storage（TLS）。

这些TLS包括_cpuset和_socket_id：
* _cpuset保存线程绑定的CPU bitmap。
* _socket_id保存CPU集合的NUMA node。如果CPU集合中有不同NUMA node的CPU，_socket_id会被设置成SOCKET_ID_ANY。
### 3.3.4. 已知问题
* rte_mempool

rte_mempool在mempool内部为每个lcore使用了一个cache。对非EAL的线程，rte_lcore_id()无法返回有效值。所以目前在非EAL线程使用rte_mempool，读写操作不会使用缺省的mempool cache，从而降低性能。在非EAL线程里，只能使用用户管理的外部cache，rte_mempool_generic_put()和rte_mempool_generic_get()可以指定cache参数。

* rte_ring

rte_ring支持多生产者入队列和多消费者出队列。但是它是非抢占的，所以rte_mempool是非抢占的。

| 注意|
| :---|
|非抢占限制的意义是：<br>* 在一个ring上执行多生产者入队列的线程不会被另一个线程抢占。<br>* 在一个ring上执行多消费者出队列的线程不会被另一个线程抢占。<br>绕过这个限制会导致第二个线程空转，直到第一个线程重新调度。而且，如果第一个线程被更高优先级的线程抢占，甚至会导致死锁。|

这里不代表不能使用，而是在同一个核上使用多线程时需要一定约束。

1. 可以在单生产者和或者单消费者情况使用。
2. 多生产者和多消费者线程的调度策略都是SCHED_OTHER(cfs)时可以使用。用户在使用时需要了解性能影响。
3. 多生产者和多消费者线程的调度策略都是SCHED_FIFO和SCHED_RR时不能使用。
* rte_timer

不允许在非EAL线程运行rte_timer_manager()。但是可以在非EAL线程重置和停止timer。

* rte_log

在非EAL线程，没有基于线程的loglevel和logtype，使用全局的loglevel。

* 其他

在非EAL线程，不支持rte_ring，rte_mempool和rte_timer的调试统计。

### 3.3.5. cgroup控制
以下是使用cgroup控制的一个简单的例子，在同一个核（$CPU）上两个线程（t0和t1）执行报文I/O。我们期望只有50%的CPU用于报文IO。
```
mkdir /sys/fs/cgroup/cpu/pkt_io
mkdir /sys/fs/cgroup/cpuset/pkt_io

echo $cpu > /sys/fs/cgroup/cpuset/cpuset.cpus

echo $t0 > /sys/fs/cgroup/cpu/pkt_io/tasks
echo $t0 > /sys/fs/cgroup/cpuset/pkt_io/tasks

echo $t1 > /sys/fs/cgroup/cpu/pkt_io/tasks
echo $t1 > /sys/fs/cgroup/cpuset/pkt_io/tasks

cd /sys/fs/cgroup/cpu/pkt_io
echo 100000 > pkt_io/cpu.cfs_period_us
echo  50000 > pkt_io/cpu.cfs_quota_us
```
## 3.4. Malloc
The EAL provides a malloc API to allocate any-sized memory.

The objective of this API is to provide malloc-like functions to allow allocation from hugepage memory and to facilitate application porting. The DPDK API Reference manual describes the available functions.

Typically, these kinds of allocations should not be done in data plane processing because they are slower than pool-based allocation and make use of locks within the allocation and free paths. However, they can be used in configuration code.

Refer to the rte_malloc() function description in the DPDK API Reference manual for more information.

### 3.4.1. Cookies
When CONFIG_RTE_MALLOC_DEBUG is enabled, the allocated memory contains overwrite protection fields to help identify buffer overflows.

### 3.4.2. Alignment and NUMA Constraints
The rte_malloc() takes an align argument that can be used to request a memory area that is aligned on a multiple of this value (which must be a power of two).

On systems with NUMA support, a call to the rte_malloc() function will return memory that has been allocated on the NUMA socket of the core which made the call. A set of APIs is also provided, to allow memory to be explicitly allocated on a NUMA socket directly, or by allocated on the NUMA socket where another core is located, in the case where the memory is to be used by a logical core other than on the one doing the memory allocation.

### 3.4.3. Use Cases
This API is meant to be used by an application that requires malloc-like functions at initialization time.

For allocating/freeing data at runtime, in the fast-path of an application, the memory pool library should be used instead.

### 3.4.4. Internal Implementation
#### 3.4.4.1. Data Structures
There are two data structure types used internally in the malloc library:

struct malloc_heap - used to track free space on a per-socket basis
struct malloc_elem - the basic element of allocation and free-space tracking inside the library.
##### 3.4.4.1.1. Structure: malloc_heap
The malloc_heap structure is used to manage free space on a per-socket basis. Internally, there is one heap structure per NUMA node, which allows us to allocate memory to a thread based on the NUMA node on which this thread runs. While this does not guarantee that the memory will be used on that NUMA node, it is no worse than a scheme where the memory is always allocated on a fixed or random node.

The key fields of the heap structure and their function are described below (see also diagram above):

lock - the lock field is needed to synchronize access to the heap. Given that the free space in the heap is tracked using a linked list, we need a lock to prevent two threads manipulating the list at the same time.
free_head - this points to the first element in the list of free nodes for this malloc heap.
Note

The malloc_heap structure does not keep track of in-use blocks of memory, since these are never touched except when they are to be freed again - at which point the pointer to the block is an input to the free() function.

![Fig. 3.2 Example of a malloc heap and malloc elements within the malloc library](https://github.com/gogodick/dpdk_prog_guide/blob/master/Image/malloc_heap.svg)


##### 3.4.4.1.2. Structure: malloc_elem
The malloc_elem structure is used as a generic header structure for various blocks of memory. It is used in three different ways - all shown in the diagram above:

As a header on a block of free or allocated memory - normal case
As a padding header inside a block of memory
As an end-of-memseg marker
The most important fields in the structure and how they are used are described below.

Note

If the usage of a particular field in one of the above three usages is not described, the field can be assumed to have an undefined value in that situation, for example, for padding headers only the “state” and “pad” fields have valid values.

heap - this pointer is a reference back to the heap structure from which this block was allocated. It is used for normal memory blocks when they are being freed, to add the newly-freed block to the heap’s free-list.
prev - this pointer points to the header element/block in the memseg immediately behind the current one. When freeing a block, this pointer is used to reference the previous block to check if that block is also free. If so, then the two free blocks are merged to form a single larger block.
next_free - this pointer is used to chain the free-list of unallocated memory blocks together. It is only used in normal memory blocks; on malloc() to find a suitable free block to allocate and on free() to add the newly freed element to the free-list.
state - This field can have one of three values: FREE, BUSY or PAD. The former two are to indicate the allocation state of a normal memory block and the latter is to indicate that the element structure is a dummy structure at the end of the start-of-block padding, i.e. where the start of the data within a block is not at the start of the block itself, due to alignment constraints. In that case, the pad header is used to locate the actual malloc element header for the block. For the end-of-memseg structure, this is always a BUSY value, which ensures that no element, on being freed, searches beyond the end of the memseg for other blocks to merge with into a larger free area.
pad - this holds the length of the padding present at the start of the block. In the case of a normal block header, it is added to the address of the end of the header to give the address of the start of the data area, i.e. the value passed back to the application on a malloc. Within a dummy header inside the padding, this same value is stored, and is subtracted from the address of the dummy header to yield the address of the actual block header.
size - the size of the data block, including the header itself. For end-of-memseg structures, this size is given as zero, though it is never actually checked. For normal blocks which are being freed, this size value is used in place of a “next” pointer to identify the location of the next block of memory that in the case of being FREE, the two free blocks can be merged into one.
#### 3.4.4.2. Memory Allocation
On EAL initialization, all memsegs are setup as part of the malloc heap. This setup involves placing a dummy structure at the end with BUSY state, which may contain a sentinel value if CONFIG_RTE_MALLOC_DEBUG is enabled, and a proper element header with FREE at the start for each memseg. The FREE element is then added to the free_list for the malloc heap.

When an application makes a call to a malloc-like function, the malloc function will first index the lcore_config structure for the calling thread, and determine the NUMA node of that thread. The NUMA node is used to index the array of malloc_heap structures which is passed as a parameter to the heap_alloc() function, along with the requested size, type, alignment and boundary parameters.

The heap_alloc() function will scan the free_list of the heap, and attempt to find a free block suitable for storing data of the requested size, with the requested alignment and boundary constraints.

When a suitable free element has been identified, the pointer to be returned to the user is calculated. The cache-line of memory immediately preceding this pointer is filled with a struct malloc_elem header. Because of alignment and boundary constraints, there could be free space at the start and/or end of the element, resulting in the following behavior:

Check for trailing space. If the trailing space is big enough, i.e. > 128 bytes, then the free element is split. If it is not, then we just ignore it (wasted space).
Check for space at the start of the element. If the space at the start is small, i.e. <=128 bytes, then a pad header is used, and the remaining space is wasted. If, however, the remaining space is greater, then the free element is split.
The advantage of allocating the memory from the end of the existing element is that no adjustment of the free list needs to take place - the existing element on the free list just has its size pointer adjusted, and the following element has its “prev” pointer redirected to the newly created element.

#### 3.4.4.3. Freeing Memory
To free an area of memory, the pointer to the start of the data area is passed to the free function. The size of the malloc_elem structure is subtracted from this pointer to get the element header for the block. If this header is of type PAD then the pad length is further subtracted from the pointer to get the proper element header for the entire block.

From this element header, we get pointers to the heap from which the block was allocated and to where it must be freed, as well as the pointer to the previous element, and via the size field, we can calculate the pointer to the next element. These next and previous elements are then checked to see if they are also FREE, and if so, they are merged with the current element. This means that we can never have two FREE memory blocks adjacent to one another, as they are always merged into a single block.

