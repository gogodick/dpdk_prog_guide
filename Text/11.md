# 11. 流量管理API
## 11.1. 概述
这是以太网设备的服务质量（QoS）流量管理的通用API，支持的主要功能有：分层调度，流量整形，拥塞管理，报文着色。这个API不涉及硬件实现，软件实现或者软硬件结合的实现。

主要功能：

* 是DPDK的rte_ethdev的API的一部分
* 每个端口，每个分层级别和每个分层节点的能力查询API
* 调度算法：严格优先级（SP），加权公平队列（WFQ）
* 流量整形：单速率和双速率，每个节点私有的整形器和多个节点共享的整形器
* 分层叶子节点的拥塞管理：尾部丢弃，头部丢弃，加权随机早期丢弃（WRED），每个节点私有的WRED上下文和多个节点共享的WRED上下文
* 报文着色：IEEE 802.1q（VLAN DEI），IETF RFC 3168（IPv4/IPv6 ECN for TCP and SCTP），IETF RFC 2597（IPv4/IPv6 DSCP）
## 11.2. 能力API
这些API的目标是为应用提供TM实现（硬件或软件）的能力信息（例如关键参数的值）。这些API支持TM级别的能力，TM的任何分层级别的能力，特定分层级别的任何节点级别的能力。这些信息帮助用户快速了解特定实现是否能够满足用户应用的需求。

在TM级别上，节点的数量，分层级别的数量，整形器的数量，私有整形器的数量，调度算法的类型（严格优先级，加权公平队列等等），这些参数由具体实现决定，帮助用户得到高层次的理解。

同样，用户可以查询分层级别的能力，获取这个级别更具体的信息。分层级别的能力查询的结果包括，这个级别的节点数量，这个级别的叶子节点和非叶子节点的数量，如果是非叶子节点对应整形器的类型（单速率，双速率）。

最后，节点级别的能力API提供了任何级别的节点支持的能力。API提供了，是否支持私有整形器，双速率整形器，整形器的最大值和最小值，等等。

## 11.3. 调度算法
基本的调度算法是严格优先级（SP）和加权公平队列（WFQ）。在调度分层的每个节点级别支持SP和WFQ算法，无论节点在树的级别和位置。SP算法用来调度优先级不同的兄弟节点，而WFQ用来调度优先级相同的兄弟组。

其他算法如负载均衡算法（WRR），字节级别的WRR，赤字WRR（DWRR）等等，和典型的WFQ类似，所以用WFQ代替这些算法，尽管精确度，性能和使用的资源可能不同。

## 11.4. 流量整形
The TM API provides support for single rate and dual rate shapers (rate limiters) for the hierarchy nodes, subject to the specific implementation support being available.

Each hierarchy node has zero or one private shaper (only one node using it) and/or zero, one or several shared shapers (multiple nodes use the same shaper instance). A private shaper is used to perform traffic shaping for a single node, while a shared shaper is used to perform traffic shaping for a group of nodes.

The configuration of private and shared shapers is done through the definition of shaper profiles. Any shaper profile (single rate or dual rate shaper) can be used by one or several shaper instances (either private or shared).

Single rate shapers use a single token bucket. Therefore, single rate shaper is configured by setting the rate of the committed bucket to zero, which effectively disables this bucket. The peak bucket is used to limit the rate and the burst size for the single rate shaper. Dual rate shapers use both the committed and the peak token buckets. The rate of the peak bucket has to be bigger than zero, as well as greater than or equal to the rate of the committed bucket.

## 11.5. Congestion Management
Congestion management is used to control the admission of packets into a packet queue or group of packet queues on congestion. The congestion management algorithms that are supported are: Tail Drop, Head Drop and Weighted Random Early Detection (WRED). They are made available for every leaf node in the hierarchy, subject to the specific implementation supporting them. On request of writing a new packet into the current queue while the queue is full, the Tail Drop algorithm drops the new packet while leaving the queue unmodified, as opposed to the Head Drop* algorithm, which drops the packet at the head of the queue (the oldest packet waiting in the queue) and admits the new packet at the tail of the queue.

The Random Early Detection (RED) algorithm works by proactively dropping more and more input packets as the queue occupancy builds up. When the queue is full or almost full, RED effectively works as Tail Drop. The Weighted RED (WRED) algorithm uses a separate set of RED thresholds for each packet color and uses separate set of RED thresholds for each packet color.

Each hierarchy leaf node with WRED enabled as its congestion management mode has zero or one private WRED context (only one leaf node using it) and/or zero, one or several shared WRED contexts (multiple leaf nodes use the same WRED context). A private WRED context is used to perform congestion management for a single leaf node, while a shared WRED context is used to perform congestion management for a group of leaf nodes.

The configuration of WRED private and shared contexts is done through the definition of WRED profiles. Any WRED profile can be used by one or several WRED contexts (either private or shared).

## 11.6. Packet Marking
The TM APIs have been provided to support various types of packet marking such as VLAN DEI packet marking (IEEE 802.1Q), IPv4/IPv6 ECN marking of TCP and SCTP packets (IETF RFC 3168) and IPv4/IPv6 DSCP packet marking (IETF RFC 2597). All VLAN frames of a given color get their DEI bit set if marking is enabled for this color. In case, when marking for a given color is not enabled, the DEI bit is left as is (either set or not).

All IPv4/IPv6 packets of a given color with ECN set to 2’b01 or 2’b10 carrying TCP or SCTP have their ECN set to 2’b11 if the marking feature is enabled for the current color, otherwise the ECN field is left as is.

All IPv4/IPv6 packets have their color marked into DSCP bits 3 and 4 as follows: green mapped to Low Drop Precedence (2’b01), yellow to Medium (2’b10) and red to High (2’b11). Marking needs to be explicitly enabled for each color; when not enabled for a given color, the DSCP field of all packets with that color is left as is.

## 11.7. Steps to Setup the Hierarchy
The TM hierarchical tree consists of leaf nodes and non-leaf nodes. Each leaf node sits on top of a scheduling queue of the current Ethernet port. Therefore, the leaf nodes have predefined IDs in the range of 0... (N-1), where N is the number of scheduling queues of the current Ethernet port. The non-leaf nodes have their IDs generated by the application outside of the above range, which is reserved for leaf nodes.

Each non-leaf node has multiple inputs (its children nodes) and single output (which is input to its parent node). It arbitrates its inputs using Strict Priority (SP) and Weighted Fair Queuing (WFQ) algorithms to schedule input packets to its output while observing its shaping (rate limiting) constraints.

The children nodes with different priorities are scheduled using the SP algorithm based on their priority, with 0 as the highest priority. Children with the same priority are scheduled using the WFQ algorithm according to their weights. The WFQ weight of a given child node is relative to the sum of the weights of all its sibling nodes that have the same priority, with 1 as the lowest weight. For each SP priority, the WFQ weight mode can be set as either byte-based or packet-based.

### 11.7.1. Initial Hierarchy Specification
The hierarchy is specified by incrementally adding nodes to build up the scheduling tree. The first node that is added to the hierarchy becomes the root node and all the nodes that are subsequently added have to be added as descendants of the root node. The parent of the root node has to be specified as RTE_TM_NODE_ID_NULL and there can only be one node with this parent ID (i.e. the root node). The unique ID that is assigned to each node when the node is created is further used to update the node configuration or to connect children nodes to it.

During this phase, some limited checks on the hierarchy specification can be conducted, usually limited in scope to the current node, its parent node and its sibling nodes. At this time, since the hierarchy is not fully defined, there is typically no real action performed by the underlying implementation.

### 11.7.2. Hierarchy Commit
The hierarchy commit API is called during the port initialization phase (before the Ethernet port is started) to freeze the start-up hierarchy. This function typically performs the following steps:

* It validates the start-up hierarchy that was previously defined for the current port through successive node add API invocations.
* Assuming successful validation, it performs all the necessary implementation specific operations to install the specified hierarchy on the current port, with immediate effect once the port is started.
This function fails when the currently configured hierarchy is not supported by the Ethernet port, in which case the user can abort or try out another hierarchy configuration (e.g. a hierarchy with less leaf nodes), which can be built from scratch or by modifying the existing hierarchy configuration. Note that this function can still fail due to other causes (e.g. not enough memory available in the system, etc.), even though the specified hierarchy is supported in principle by the current port.

### 11.7.3. Run-Time Hierarchy Updates
The TM API provides support for on-the-fly changes to the scheduling hierarchy, thus operations such as node add/delete, node suspend/resume, parent node update, etc., can be invoked after the Ethernet port has been started, subject to the specific implementation supporting them. The set of dynamic updates supported by the implementation is advertised through the port capability set.
